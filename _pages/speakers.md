---
layout: page
permalink: /speakers/
title: Speakers
description: We are excited to feature eight distinguished speakers who bring diverse perspectives from philosophy, cognitive science, and artificial intelligence to explore fundamental questions about LLMs and the nature of mind.
nav: true
nav_order: 1
---

<div class="speakers-content">
  <div class="speakers-grid">
    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/david_chalmers.jpg" alt="David Chalmers" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">David Chalmers</h3>
        <p class="speaker-affiliation">New York University</p>
        <div class="speaker-bio">
          <p>David Chalmers is University Professor of Philosophy and Neural Science and co-director of the Center for Mind, Brain, and Consciousness at New York University. He is the author of <em>The Conscious Mind</em> (1996), <em>Constructing The World</em> (2010), and <em>Reality+: Virtual Worlds and the Problems of Philosophy</em> (2022). He is known for formulating the "hard problem" of consciousness, which inspired Tom Stoppard's play <em>The Hard Problem</em>, and for the idea of the "extended mind," which says that the tools we use can become parts of our minds. He is widely regarded as one of the most important living philosophers, whose work has transformative impact on numerous disciplines, including the development of artificial intelligence.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/melanie_mitchell.jpg" alt="Melanie Mitchell" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Melanie Mitchell</h3>
        <p class="speaker-affiliation">Santa Fe Institute</p>
        <div class="speaker-bio">
          <p>Melanie Mitchell is a Professor at Santa Fe Institute. She previously held faculty or research positions at the University of Michigan, the Santa Fe Institute, Los Alamos National Laboratory, the Oregon Graduate Institute, and Portland State University, and received her PhD in Computer Science from the University of Michigan. Her recent research focuses on conceptual abstraction and analogy-making in humans and in artificial intelligence systems. Melanie is the author or editor of six books and over 100 scholarly papers in the fields of artificial intelligence, cognitive science, and complex systems.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/been_kim.jpg" alt="Been Kim" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Been Kim</h3>
        <p class="speaker-affiliation">Google DeepMind</p>
        <div class="speaker-bio">
          <p>Been Kim is a Senior Staff Research Scientist at Google DeepMind, dedicated to fostering effective communication and collaboration between humans and complex machine learning models. Her research aims to harness machine intelligence for human benefit. Notably, her recent work in teaching superhuman chess concepts to grandmasters, one of them becoming the youngest World Chess Champion (Gukesh). Dr. Kim is an accomplished speaker, having given a talk at the G20 meeting in Argentina (2019) and keynotes at ICLR (2022) and ECML (2020).</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/daniel_rothschild.jpg" alt="Daniel Rothschild" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Daniel Rothschild</h3>
        <p class="speaker-affiliation">University College London</p>
        <div class="speaker-bio">
          <p>Daniel Rothschild is Professor of Philosophy of Language at UCL. Previously, Rothschild held faculty positions at Columbia University, Yale University, and All Souls College, Oxford. Rothschild's work focuses on language, knowledge and their interaction, and is known for his significant contributions to epistemology and the philosophy of language in general. Recently, Rothschild has written on the implications of large language models for philosophy of mind and he is currently working on a book about the relationship between machine learning and human learning.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/yilun_du.jpg" alt="Yilun Du" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Yilun Du</h3>
        <p class="speaker-affiliation">Harvard University / Google DeepMind</p>
        <div class="speaker-bio">
          <p>Yilun Du is an assistant professor at Harvard in the Kempner Institute and Computer Science. He was previously a senior research scientist at Google DeepMind and received his PhD from MIT. His research focuses on generative models, decision making, robot learning, embodied agents, and the applications of such tools to scientific domains. His research is driven by the goal of developing intelligent embodied agents in the physical world.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/raphael_milliere.jpg" alt="RaphaÃ«l MilliÃ¨re" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">RaphaÃ«l MilliÃ¨re</h3>
        <p class="speaker-affiliation">Macquarie University / University of Oxford</p>
        <div class="speaker-bio">
          <p>RaphaÃ«l MilliÃ¨re is Assistant Professor in Philosophy of AI at Macquarie University in Sydney and incoming Associate Professor at the University of Oxford. He is also an AI2050 Fellow (Schmidt Sciences) and an Australian Research Council DECRA Fellow. His research focuses on foundational questions regarding the capacities and limitations of modern deep neural networks, particularly language models. It addresses both first-order questions about whether these systems exhibit specific cognitive capacities, and second-order methodological challenges involved in evaluating these cognitive capacities in neural networks.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/ziming_liu.jpg" alt="Ziming Liu" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Ziming Liu</h3>
        <p class="speaker-affiliation">MIT / Tsinghua University</p>
        <div class="speaker-bio">
          <p>Ziming Liu is an incoming assistant professor at Tsinghua University and a final-year PhD student at the Massachusetts Institute of Technology (MIT). His research bridges Science for AIâ€”leveraging scientific principles to design and understand AI modelsâ€”and AI for Scienceâ€”applying AI to accelerate scientific discovery. Ziming's work has attracted wide attention in both the AI and physics communities, including a notable contribution to the development of Kolmogorov-Arnold Networks.</p>
        </div>
      </div>
    </div>

    <div class="speaker-card">
      <div class="speaker-image-container">
        <img src="/assets/img/speakers/ellie_pavlick.jpg" alt="Ellie Pavlick" class="speaker-image">
      </div>
      <div class="speaker-info">
        <h3 class="speaker-name">Ellie Pavlick</h3>
        <p class="speaker-affiliation">Brown University & Google DeepMind</p>
        <div class="speaker-bio">
          <p>Ellie Pavlick is an Associate Professor of Computer Science, Cognitive Science, and Linguistics at Brown University, and a Research Scientist at Google DeepMind. She leads the Language Understanding and Representation (LUNAR) Lab, which seeks to understand how language "works" and to build computational models which can understand language the way that humans do. Her lab's projects focus on language broadly construed, and often includes the study of capacities more general than language, including conceptual representations, reasoning, learning, and generalization.</p>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
.speakers-hero {
  background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
  color: white;
  padding: 4rem 2rem;
  border-radius: 20px;
  margin-bottom: 3rem;
  position: relative;
  overflow: hidden;
}

.hero-content {
  max-width: 800px;
  margin: 0 auto;
  text-align: center;
  position: relative;
  z-index: 2;
}

.hero-title {
  font-size: 3.5rem;
  font-weight: 700;
  margin-bottom: 1rem;
  background: linear-gradient(45deg, #fff, #e0f7ff);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
}

.hero-subtitle {
  font-size: 1.4rem;
  margin-bottom: 2rem;
  opacity: 0.9;
}

.speaker-count {
  display: inline-block;
  background: rgba(255, 255, 255, 0.2);
  backdrop-filter: blur(10px);
  border: 1px solid rgba(255, 255, 255, 0.3);
  border-radius: 15px;
  padding: 1rem 2rem;
  text-align: center;
}

.count-number {
  display: block;
  font-size: 2.5rem;
  font-weight: 700;
  margin-bottom: 0.5rem;
}

.count-label {
  display: block;
  font-size: 0.9rem;
  opacity: 0.8;
}

.floating-elements {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
}

.element {
  position: absolute;
  font-size: 2rem;
  opacity: 0.1;
  animation: float 6s ease-in-out infinite;
}

.element:nth-child(1) { top: 20%; left: 10%; animation-delay: 0s; }
.element:nth-child(2) { top: 60%; right: 15%; animation-delay: 2s; }
.element:nth-child(3) { bottom: 20%; left: 20%; animation-delay: 4s; }

@keyframes float {
  0%, 100% { transform: translateY(0px) rotate(0deg); }
  50% { transform: translateY(-20px) rotate(5deg); }
}

.speakers-content {
  max-width: 1400px;
  margin: 0 auto;
  padding: 0 2rem;
}

.speakers-introduction {
  text-align: center;
  margin-bottom: 4rem;
}

.speakers-introduction h2 {
  font-size: 2.5rem;
  color: #333;
  margin-bottom: 1rem;
}

.intro-text {
  font-size: 1.2rem;
  line-height: 1.8;
  color: #666;
  max-width: 900px;
  margin: 0 auto;
}

.speakers-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
  gap: 2rem;
}

.speaker-card {
  background: white;
  border-radius: 20px;
  overflow: hidden;
  box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
  transition: all 0.3s ease;
  border: 1px solid #f0f0f0;
  text-align: center;
  padding: 2rem;
}

.speaker-card:hover {
  transform: translateY(-5px);
  box-shadow: 0 15px 35px rgba(0, 0, 0, 0.15);
}

.speaker-image-container {
  position: relative;
  width: 120px;
  height: 120px;
  margin: 0 auto 1.5rem auto;
  border-radius: 50%;
  background: linear-gradient(135deg, #f0f2f5 0%, #e1e8ed 100%);
  display: flex;
  align-items: center;
  justify-content: center;
  border: 4px solid #4facfe;
  overflow: hidden;
}

.speaker-image-container::before {
  content: 'ðŸ‘¤';
  position: absolute;
  font-size: 3rem;
  color: #ccc;
  z-index: 1;
}

.speaker-image {
  width: 100%;
  height: 100%;
  object-fit: cover;
  border-radius: 50%;
  transition: transform 0.3s ease;
  position: relative;
  z-index: 2;
  background: #f8f9fa;
}

.speaker-image:not([src]), 
.speaker-image[src=""], 
.speaker-image[src*="placeholder"] {
  opacity: 0;
}

.speaker-card:hover .speaker-image {
  transform: scale(1.05);
}

.speaker-card:hover .speaker-image-container {
  border-color: #00f2fe;
}

.speaker-overlay {
  position: absolute;
  top: 5px;
  right: 5px;
  z-index: 3;
}

.speaker-status {
  background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
  color: white;
  width: 24px;
  height: 24px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.7rem;
  font-weight: 700;
  box-shadow: 0 2px 8px rgba(40, 167, 69, 0.3);
  border: 2px solid white;
}

.speaker-status::before {
  content: "âœ“";
  font-size: 0.8rem;
}

.speaker-info {
  padding: 0;
}

.speaker-name {
  font-size: 1.3rem;
  color: #333;
  margin-bottom: 0.5rem;
  font-weight: 700;
}

.speaker-affiliation {
  color: #4facfe;
  font-weight: 600;
  margin-bottom: 1.5rem;
  font-size: 1rem;
}

.speaker-bio {
  margin-bottom: 0;
}

.speaker-bio p {
  color: #666;
  line-height: 1.6;
  font-size: 0.95rem;
}

@media (max-width: 768px) {
  .hero-title {
    font-size: 2.5rem;
  }
  
  .speakers-grid {
    grid-template-columns: 1fr;
  }
  
  .speaker-card {
    margin-bottom: 1rem;
  }
}
</style> 